#!/usr/bin/env python3
"""
Robust Universal Extractor - æ¼”ç¤ºè„šæœ¬
å±•ç¤ºæ–°çš„è§†è§‰ç»“æ„åˆ†æåŠŸèƒ½
"""

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from core.robust_extractor import RobustUniversalExtractor, extract_robust
from core.visual_analyzer import VisualStructureAnalyzer


def demo_visual_analysis(url: str = None):
    """æ¼”ç¤ºè§†è§‰ç»“æ„åˆ†æ"""
    from crawler.html_fetcher import HTMLFetcher
    
    if not url:
        url = "https://www.h3c.com/en/Products_and_Solutions/InterConnect/Switches/Products/Campus_Network/Access/S5130/H3C_S5130S_EI/"
    
    print("=" * 70)
    print("ğŸ‰ å¥å£®ç‰ˆé€šç”¨æå–å™¨ - è§†è§‰ç»“æ„åˆ†ææ¼”ç¤º")
    print("=" * 70)
    print(f"\nğŸ“ ç›®æ ‡URL: {url}")
    print("\nğŸ”„ æ­£åœ¨è·å–é¡µé¢...")
    
    fetcher = HTMLFetcher(delay=1.5)
    html = fetcher.fetch(url)
    
    print("âœ… é¡µé¢è·å–æˆåŠŸ")
    print("\n" + "-" * 70)
    
    # 1. æ‰§è¡Œå®Œæ•´æå–æµç¨‹
    print("\nğŸ” æ‰§è¡Œå®Œæ•´æå–åˆ†ææµç¨‹...\n")
    
    extractor = RobustUniversalExtractor()
    result = extractor.extract_with_analysis(html, url)
    
    # 2. æ˜¾ç¤ºåˆ†ææŠ¥å‘Š
    print(extractor.get_detailed_report())
    
    # 3. æ˜¾ç¤ºæå–ç»“æœæ‘˜è¦
    print("\nğŸ“Š æå–ç»“æœæ‘˜è¦:")
    print("-" * 70)
    
    data = result['data']
    print(f"âœ… æˆåŠŸæå– {len(data)} ä¸ªå‹å·")
    
    if data:
        sample_model = list(data.keys())[0]
        print(f"\nğŸ“‹ æ ·æœ¬å‹å·: {sample_model}")
        sample_data = data[sample_model]
        
        print(f"   å­—æ®µæ•°é‡: {len(sample_data)}")
        print(f"   ä¸»è¦å­—æ®µ:")
        for key in list(sample_data.keys())[:10]:
            value = sample_data[key]
            display_value = str(value)[:40] + "..." if len(str(value)) > 40 else str(value)
            print(f"      - {key}: {display_value}")
    
    # 4. æ˜¾ç¤ºæ”¹è¿›å»ºè®®
    recommendations = result.get('recommendations', [])
    if recommendations:
        print(f"\nğŸ’¡ å‘ç° {len(recommendations)} æ¡æ”¹è¿›å»ºè®®:")
        print("-" * 70)
        for i, rec in enumerate(recommendations[:5], 1):
            print(f"{i}. [{rec['priority'].upper()}] {rec['category']}")
            print(f"   {rec['message']}")
            print(f"   å»ºè®®æ“ä½œ: {rec.get('action', 'N/A')}")
            print()
    
    # 5. ç”Ÿæˆé…ç½®æ¨¡æ¿
    print("\nğŸ“ ç”Ÿæˆé…ç½®æ¨¡æ¿ç‰‡æ®µ:")
    print("-" * 70)
    config_template = extractor.generate_config_template(html, url)
    print(config_template[:1500] + "\n... (truncated)")
    
    print("\n" + "=" * 70)
    print("âœ¨ æ¼”ç¤ºå®Œæˆ!")
    print("=" * 70)
    print("\nä½¿ç”¨è¯´æ˜:")
    print("  1. å¦‚éœ€äº¤äº’å¼é…ç½®: extract_robust(html, url, interactive=True)")
    print("  2. ä»…åˆ†æé¡µé¢: analyze_page(html, url)")
    print("  3. ç”Ÿæˆé…ç½®: extractor.generate_config_template(html, url)")


def demo_compare_profiles():
    """æ¼”ç¤ºä¸åŒé…ç½®çš„å¯¹æ¯”"""
    print("\n" + "=" * 70)
    print("ğŸ“š å¯ç”¨é…ç½®æ–‡ä»¶å¯¹æ¯”")
    print("=" * 70)
    
    from core.rule_engine import get_rule_engine
    
    engine = get_rule_engine("config")
    profiles = engine.list_profiles()
    
    print(f"\nå‘ç° {len(profiles)} ä¸ªé…ç½®æ–‡ä»¶:\n")
    
    for p in profiles:
        print(f"  ğŸ“„ {p['name']}")
        print(f"     å“ç‰Œ: {p['brand']}")
        print(f"     ç±»å‹: {p['type']} ({p['sub_type']})")
        print(f"     ç‰ˆæœ¬: {p['version']}")
        print()


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Robust Universal Extractor Demo')
    parser.add_argument('--url', '-u', help='Target URL to analyze')
    parser.add_argument('--list-profiles', '-l', action='store_true', 
                       help='List available profiles')
    
    args = parser.parse_args()
    
    if args.list_profiles:
        demo_compare_profiles()
    else:
        demo_visual_analysis(args.url)


if __name__ == "__main__":
    main()
